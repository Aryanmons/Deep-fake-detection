{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPTAXYTEMqiTfoASggmAOQL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Krushna-sahoo/Deep-fake-detection/blob/main/extraction_and_combination.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsn1o2l6y_Cm",
        "outputId": "e29a79d2-3106-439e-f324-2447a7c7c742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless facenet-pytorch numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSIYrLP50YEQ",
        "outputId": "8719ced7-c772-4643-9587-c203583b1599"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: facenet-pytorch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: Pillow<10.3.0,>=10.2.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (10.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (2.32.3)\n",
            "Requirement already satisfied: torch<2.3.0,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (2.2.2)\n",
            "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (0.17.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3.0,>=2.2.0->facenet-pytorch) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from facenet_pytorch import MTCNN\n",
        "\n",
        "#  Define paths\n",
        "VIDEO_FOLDER = \"/content/drive/MyDrive/Deep-fake-detection\"  # Folder with raw videos\n",
        "OUTPUT_FOLDER = \"/content/drive/MyDrive/Deep-fake-detection/processed_faces\"  # Folder for face-only videos\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "#  Initialize MTCNN\n",
        "mtcnn = MTCNN(keep_all=False, select_largest=True)\n",
        "\n",
        "def process_video(video_path, output_path, frame_limit=100):\n",
        "    \"\"\"Extract face from each frame and create a face-only video.\"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = 0\n",
        "    face_frames = []\n",
        "\n",
        "    while cap.isOpened() and frame_count < frame_limit:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Convert BGR to RGB for MTCNN\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Detect face and get bounding box\n",
        "        boxes, _ = mtcnn.detect(rgb_frame)\n",
        "\n",
        "        if boxes is not None and len(boxes) > 0:\n",
        "            x1, y1, x2, y2 = map(int, boxes[0])  # Get first detected face\n",
        "\n",
        "            # Ensure bounding box is within image bounds\n",
        "            h, w, _ = frame.shape\n",
        "            x1, y1, x2, y2 = max(0, x1), max(0, y1), min(w, x2), min(h, y2)\n",
        "\n",
        "            # Extract face from original BGR image\n",
        "            face = frame[y1:y2, x1:x2]\n",
        "\n",
        "            if face.size > 0:\n",
        "                # Resize for consistency\n",
        "                face_resized = cv2.resize(face, (160, 160), interpolation=cv2.INTER_LANCZOS4)\n",
        "\n",
        "                # Store extracted face frame\n",
        "                face_frames.append(face_resized)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # Convert extracted faces into a new video\n",
        "    if len(face_frames) > 0:\n",
        "        height, width, _ = face_frames[0].shape\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        fps = 10  # Adjust FPS as needed\n",
        "        video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        for face in face_frames:\n",
        "            video_writer.write(face)\n",
        "\n",
        "        video_writer.release()\n",
        "        print(f\"Face-only video saved: {output_path}\")\n",
        "    else:\n",
        "        print(f\"No faces detected in {video_path}\")\n",
        "\n",
        "def process_all_videos(video_folder, output_folder, frame_limit=100):\n",
        "    \"\"\"Process all videos in a folder and generate face-only videos.\"\"\"\n",
        "    video_files = [f for f in os.listdir(video_folder) if f.endswith('.mp4')]\n",
        "\n",
        "    if not video_files:\n",
        "        print(\" No videos found in the folder!\")\n",
        "        return\n",
        "\n",
        "    for video_file in video_files:\n",
        "        video_path = os.path.join(video_folder, video_file)\n",
        "        output_path = os.path.join(output_folder, f\"processed_{video_file}\")\n",
        "\n",
        "        print(f\" Processing: {video_file}\")\n",
        "        process_video(video_path, output_path, frame_limit)\n",
        "\n",
        "#  Process all videos in the folder\n",
        "process_all_videos(VIDEO_FOLDER, OUTPUT_FOLDER)\n",
        "\n",
        "print(\" Face-only dataset creation complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjKpPCFmzHgQ",
        "outputId": "42737938-7d69-4611-ebb0-f306f744f076"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Processing: id9_id16_0000.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/Deep-fake-detection/processed_faces/processed_id9_id16_0000.mp4\n",
            " Processing: id9_id16_0002.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/Deep-fake-detection/processed_faces/processed_id9_id16_0002.mp4\n",
            " Processing: id9_id16_0008.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/Deep-fake-detection/processed_faces/processed_id9_id16_0008.mp4\n",
            " Processing: id9_id16_0001.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/Deep-fake-detection/processed_faces/processed_id9_id16_0001.mp4\n",
            " Processing: id9_id16_0003.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/Deep-fake-detection/processed_faces/processed_id9_id16_0003.mp4\n",
            " Processing: id9_id16_0005.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/Deep-fake-detection/processed_faces/processed_id9_id16_0005.mp4\n",
            " Processing: id9_id16_0007.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/Deep-fake-detection/processed_faces/processed_id9_id16_0007.mp4\n",
            " Processing: id9_id16_0009.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/Deep-fake-detection/processed_faces/processed_id9_id16_0009.mp4\n",
            " Processing: id9_id16_0004.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/Deep-fake-detection/processed_faces/processed_id9_id16_0004.mp4\n",
            " Processing: id9_id16_0006.mp4\n",
            "Face-only video saved: /content/drive/MyDrive/Deep-fake-detection/processed_faces/processed_id9_id16_0006.mp4\n",
            " Face-only dataset creation complete!\n"
          ]
        }
      ]
    }
  ]
}